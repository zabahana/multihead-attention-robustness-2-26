{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Multi-Head Diversity: Randomized Stressors & Robustness Visualization\n",
        "\n",
        "**Randomized stressors** (not worst-case PGD/FGSM or certified): Finance-valid attacks A1–A4 as distributional stress tests.\n",
        "\n",
        "**Model**: Multi-Head Diversity only.\n",
        "\n",
        "**Metrics**: R²-based and RMSE-based robustness, with rich visualizations common in adversarial training and certification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "USE_SMALL_DATA = True\n",
        "N_SAMPLES = 5000\n",
        "N_EPOCHS = 30\n",
        "N_STRESS_RUNS = 5  # Number of random runs per (attack, epsilon) for robustness CI"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "    print('Google Drive mounted.')\n",
        "except Exception:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys, os\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import random\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "RANDOM_SEED = 42\n",
        "random.seed(RANDOM_SEED)\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "def _find_repo_root():\n",
        "    cwd = Path.cwd().resolve()\n",
        "    for p in [Path('/content/drive/MyDrive/multihead-attention-robustness'), Path('/content/drive/My Drive/multihead-attention-robustness'), Path('/content/repo_run')]:\n",
        "        if p.exists() and (p / 'src').exists():\n",
        "            return p\n",
        "    drive_root = Path('/content/drive')\n",
        "    if drive_root.exists():\n",
        "        for base in [drive_root / 'MyDrive', drive_root / 'My Drive', drive_root]:\n",
        "            if base.exists():\n",
        "                for sub in base.iterdir():\n",
        "                    if sub.is_dir() and 'multihead-attention' in sub.name.lower() and (sub / 'src').exists():\n",
        "                        return sub\n",
        "    p = cwd\n",
        "    for _ in range(10):\n",
        "        if (p / 'src').exists():\n",
        "            return p\n",
        "        if p.parent == p:\n",
        "            break\n",
        "        p = p.parent\n",
        "    return cwd.parent if cwd.name == 'notebooks' else cwd\n",
        "\n",
        "repo_root = _find_repo_root()\n",
        "if not (repo_root / 'src').exists():\n",
        "    raise FileNotFoundError(f\"Repo root not found. Run Drive mount first.\")\n",
        "sys.path.insert(0, str(repo_root))\n",
        "os.chdir(repo_root)\n",
        "from src.models.feature_token_transformer import FeatureTokenTransformer\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Device: {device}, Repo: {repo_root}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "data_path = repo_root / 'data' / 'cross_sectional' / 'master_table.csv'\n",
        "if not data_path.exists():\n",
        "    data_path = repo_root / 'data' / 'master_table.csv'\n",
        "df = pd.read_csv(data_path)\n",
        "if 'date' in df.columns:\n",
        "    df['date'] = pd.to_datetime(df['date'])\n",
        "    df = df.set_index('date')\n",
        "\n",
        "class CrossSectionalDataSplitter:\n",
        "    def __init__(self, train_start='2005-01-01', train_end='2017-12-31', val_start='2018-01-01', val_end='2019-12-31'):\n",
        "        self.train_start, self.train_end = train_start, train_end\n",
        "        self.val_start, self.val_end = val_start, val_end\n",
        "    def split(self, master_table):\n",
        "        master_table = master_table.copy()\n",
        "        master_table.index = pd.to_datetime(master_table.index)\n",
        "        return {'train': master_table.loc[self.train_start:self.train_end], 'val': master_table.loc[self.val_start:self.val_end]}\n",
        "    def prepare_features_labels(self, data):\n",
        "        if data.empty:\n",
        "            return pd.DataFrame(), pd.Series()\n",
        "        numeric_data = data.select_dtypes(include=[np.number])\n",
        "        if numeric_data.empty:\n",
        "            return pd.DataFrame(), pd.Series()\n",
        "        exclude_cols = ['mktcap', 'market_cap', 'date', 'year', 'month', 'ticker', 'permno', 'gvkey']\n",
        "        target_cols = ['return', 'returns', 'ret', 'target', 'y', 'next_return', 'forward_return', 'ret_1', 'ret_1m', 'ret_12m', 'future_return', 'returns_1d']\n",
        "        target_col = None\n",
        "        for tc in target_cols:\n",
        "            for col in numeric_data.columns:\n",
        "                if tc.lower() in col.lower() and col.lower() not in [ec.lower() for ec in exclude_cols]:\n",
        "                    target_col = col\n",
        "                    break\n",
        "            if target_col:\n",
        "                break\n",
        "        if target_col is None:\n",
        "            potential = [c for c in numeric_data.columns if c.lower() not in [ec.lower() for ec in exclude_cols]]\n",
        "            target_col = potential[-2] if len(potential) > 1 else (potential[-1] if potential else numeric_data.columns[-1])\n",
        "        feature_cols = [c for c in numeric_data.columns if c != target_col and c.lower() not in [ec.lower() for ec in exclude_cols]]\n",
        "        if not feature_cols:\n",
        "            feature_cols = [c for c in numeric_data.columns if c != target_col]\n",
        "        if not feature_cols:\n",
        "            feature_cols = numeric_data.columns[:-1].tolist()\n",
        "            target_col = numeric_data.columns[-1]\n",
        "        return numeric_data[feature_cols], numeric_data[target_col]\n",
        "\n",
        "splitter = CrossSectionalDataSplitter()\n",
        "data_splits = splitter.split(df)\n",
        "train_df, val_df = data_splits['train'], data_splits['val']\n",
        "X_train_df, y_train = splitter.prepare_features_labels(train_df)\n",
        "X_val_df, y_val = splitter.prepare_features_labels(val_df)\n",
        "X_train = X_train_df.fillna(0).values.astype(np.float32)\n",
        "y_train = y_train.fillna(0).values.astype(np.float32)\n",
        "X_val = X_val_df.fillna(0).values.astype(np.float32)\n",
        "y_val = y_val.fillna(0).values.astype(np.float32)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "if USE_SMALL_DATA and N_SAMPLES < len(X_train):\n",
        "    idx = np.random.RandomState(RANDOM_SEED).choice(len(X_train), N_SAMPLES, replace=False)\n",
        "    X_train_scaled, y_train = X_train_scaled[idx], y_train[idx]\n",
        "\n",
        "sigma_train = np.std(X_train_scaled, axis=0) + 1e-8\n",
        "val_dates = X_val_df.index if hasattr(X_val_df, 'index') else None\n",
        "print(f'Data: train {X_train_scaled.shape[0]}, val {X_val_scaled.shape[0]}, features {X_train_scaled.shape[1]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Randomized Stressors (A1–A4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def apply_a1(X, epsilon, sigma):\n",
        "    \"\"\"A1: Measurement Error - η_i ~ N(0, ε²I) per sample.\"\"\"\n",
        "    eta = np.random.normal(0, epsilon, X.shape)\n",
        "    return X + eta * sigma\n",
        "\n",
        "def apply_a2(X, epsilon):\n",
        "    \"\"\"A2: Missingness - zero fraction p = min(ε/10, 0.8) of features.\"\"\"\n",
        "    p = min(epsilon / 10.0, 0.8)\n",
        "    X_adv = X.copy()\n",
        "    n_samples, n_features = X.shape\n",
        "    n_missing = max(1, int(n_features * p))\n",
        "    for i in range(n_samples):\n",
        "        idx = np.random.choice(n_features, n_missing, replace=False)\n",
        "        X_adv[i, idx] = 0.0\n",
        "    return X_adv\n",
        "\n",
        "def apply_a3(X, epsilon, sigma):\n",
        "    \"\"\"A3: Rank Manipulation - δ_i,j ~ N(0, ε² σ_j²).\"\"\"\n",
        "    delta = np.random.normal(0, epsilon, X.shape) * sigma\n",
        "    return X + delta\n",
        "\n",
        "def apply_a4(X, epsilon, sigma):\n",
        "    \"\"\"A4: Regime Shift - shared η_t across samples (simplified: per batch).\"\"\"\n",
        "    eta = np.random.normal(0, 1, X.shape[1])\n",
        "    return X + epsilon * sigma * eta\n",
        "\n",
        "ATTACKS = {'A1': 'Measurement Error', 'A2': 'Missingness', 'A3': 'Rank Manipulation', 'A4': 'Regime Shift'}\n",
        "EPSILONS = [0.25, 0.5, 1.0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Train Multi-Head Diversity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def train_mhd(model, X_train, y_train, X_val, y_val, config, device):\n",
        "    model = model.to(device)\n",
        "    criterion = nn.MSELoss()\n",
        "    opt = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
        "    X_t = torch.FloatTensor(X_train).to(device)\n",
        "    y_t = torch.FloatTensor(y_train).to(device)\n",
        "    X_v = torch.FloatTensor(X_val).to(device)\n",
        "    batch_size = config['batch_size']\n",
        "    for epoch in range(config['epochs']):\n",
        "        model.train()\n",
        "        for i in range(0, len(X_t), batch_size):\n",
        "            bx, by = X_t[i:i+batch_size], y_t[i:i+batch_size]\n",
        "            opt.zero_grad()\n",
        "            pred, attn = model(bx)\n",
        "            loss = criterion(pred.squeeze(), by)\n",
        "            if model.use_head_diversity and attn:\n",
        "                loss = loss + model.compute_diversity_loss([attn[f'layer_{j}'] for j in range(len(attn))])\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            opt.step()\n",
        "        if (epoch + 1) % 20 == 0:\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                p, _ = model(X_v)\n",
        "                vloss = criterion(p.squeeze(), torch.FloatTensor(y_val).to(device))\n",
        "            print(f'  Epoch {epoch+1}: val_loss={vloss.item():.6f}')\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        pred, _ = model(X_v)\n",
        "        pred = pred.squeeze().cpu().numpy()\n",
        "    return model, pred\n",
        "\n",
        "tr_cfg = {'d_model': 72, 'num_layers': 2, 'd_ff': 512, 'dropout': 0.1, 'learning_rate': 0.0001, 'batch_size': 32, 'epochs': N_EPOCHS if USE_SMALL_DATA else 100}\n",
        "model = FeatureTokenTransformer(num_features=X_train_scaled.shape[1], d_model=tr_cfg['d_model'], num_heads=8, num_layers=tr_cfg['num_layers'], d_ff=tr_cfg['d_ff'], dropout=tr_cfg['dropout'], use_head_diversity=True, diversity_weight=0.01)\n",
        "model, pred_clean = train_mhd(model, X_train_scaled, y_train, X_val_scaled, y_val, tr_cfg, device)\n",
        "\n",
        "clean_rmse = np.sqrt(mean_squared_error(y_val, pred_clean))\n",
        "clean_r2 = r2_score(y_val, pred_clean)\n",
        "print(f'Clean: RMSE={clean_rmse:.6f}, R²={clean_r2:.6f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Evaluate Under Stressors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def evaluate_under_stress(model, X_val, y_val, sigma, attack_name, epsilon, n_runs, device, clean_rmse, clean_r2):\n",
        "    model.eval()\n",
        "    rmses, r2s, rob_rmse, rob_r2 = [], [], [], []\n",
        "    for _ in range(n_runs):\n",
        "        if attack_name == 'A1':\n",
        "            X_adv = apply_a1(X_val, epsilon, sigma)\n",
        "        elif attack_name == 'A2':\n",
        "            X_adv = apply_a2(X_val, epsilon)\n",
        "        elif attack_name == 'A3':\n",
        "            X_adv = apply_a3(X_val, epsilon, sigma)\n",
        "        elif attack_name == 'A4':\n",
        "            X_adv = apply_a4(X_val, epsilon, sigma)\n",
        "        else:\n",
        "            X_adv = X_val.copy()\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            X_t = torch.FloatTensor(X_adv).to(device)\n",
        "            pred, _ = model(X_t)\n",
        "            pred = pred.squeeze().cpu().numpy()\n",
        "        \n",
        "        rmse = np.sqrt(mean_squared_error(y_val, pred))\n",
        "        r2 = r2_score(y_val, pred)\n",
        "        rmses.append(rmse)\n",
        "        r2s.append(r2)\n",
        "        delta_rmse = rmse - clean_rmse\n",
        "        rob_rmse.append(min(1.0, 1.0 - delta_rmse / clean_rmse) if clean_rmse > 0 else 1.0)\n",
        "        rob_r2.append(min(1.0, r2 / clean_r2) if clean_r2 > 0 else 1.0)\n",
        "    \n",
        "    return {'rmse_mean': np.mean(rmses), 'rmse_std': np.std(rmses), 'r2_mean': np.mean(r2s), 'r2_std': np.std(r2s),\n",
        "            'rob_rmse_mean': np.mean(rob_rmse), 'rob_rmse_std': np.std(rob_rmse),\n",
        "            'rob_r2_mean': np.mean(rob_r2), 'rob_r2_std': np.std(rob_r2),\n",
        "            'delta_rmse': np.mean(rmses) - clean_rmse}\n",
        "\n",
        "results = []\n",
        "for attack in ATTACKS:\n",
        "    for eps in EPSILONS:\n",
        "        r = evaluate_under_stress(model, X_val_scaled, y_val, sigma_train, attack, eps, N_STRESS_RUNS, device, clean_rmse, clean_r2)\n",
        "        results.append({'attack': attack, 'epsilon': eps, **r})\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(results_df.to_string())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Visualizations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "\n",
        "# 1. RMSE-based robustness vs epsilon\n",
        "ax = axes[0, 0]\n",
        "for attack in ATTACKS:\n",
        "    d = results_df[results_df['attack'] == attack]\n",
        "    ax.errorbar(d['epsilon'], d['rob_rmse_mean'], yerr=d['rob_rmse_std'], fmt='o-', label=attack, capsize=3)\n",
        "ax.axhline(1.0, color='gray', linestyle='--', alpha=0.5)\n",
        "ax.set_xlabel('ε (perturbation budget)')\n",
        "ax.set_ylabel('Robustness (RMSE-based)')\n",
        "ax.set_title('RMSE-based Robustness: R = min(1, 1 - ΔRMSE/RMSE_clean)')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. R² degradation vs epsilon\n",
        "ax = axes[0, 1]\n",
        "for attack in ATTACKS:\n",
        "    d = results_df[results_df['attack'] == attack]\n",
        "    ax.errorbar(d['epsilon'], d['r2_mean'], yerr=d['r2_std'], fmt='s-', label=attack, capsize=3)\n",
        "ax.axhline(clean_r2, color='gray', linestyle='--', alpha=0.5, label='Clean')\n",
        "ax.set_xlabel('ε')\n",
        "ax.set_ylabel('R² under stress')\n",
        "ax.set_title('R² Degradation Under Randomized Stressors')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Heatmap: RMSE-based robustness\n",
        "ax = axes[1, 0]\n",
        "pivot = results_df.pivot(index='attack', columns='epsilon', values='rob_rmse_mean')\n",
        "sns.heatmap(pivot, annot=True, fmt='.3f', cmap='RdYlGn', vmin=0.5, vmax=1.0, ax=ax)\n",
        "ax.set_title('Robustness Heatmap (RMSE-based)')\n",
        "\n",
        "# 4. ΔRMSE by attack and epsilon\n",
        "ax = axes[1, 1]\n",
        "x = np.arange(len(ATTACKS))\n",
        "width = 0.25\n",
        "for i, eps in enumerate(EPSILONS):\n",
        "    vals = [results_df[(results_df['attack']==a) & (results_df['epsilon']==eps)]['delta_rmse'].values[0] for a in ATTACKS]\n",
        "    ax.bar(x + i*width, vals, width, label=f'ε={eps}')\n",
        "ax.set_xticks(x + width)\n",
        "ax.set_xticklabels(list(ATTACKS))\n",
        "ax.set_ylabel('ΔRMSE')\n",
        "ax.set_title('RMSE Degradation (ΔRMSE = RMSE_adv - RMSE_clean)')\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.suptitle('Multi-Head Diversity: Randomized Stressors (A1–A4)', fontsize=12, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# R²-based robustness heatmap\n",
        "if 'rob_r2_mean' in results_df.columns:\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(6, 4))\n",
        "    pivot_r2 = results_df.pivot(index='attack', columns='epsilon', values='rob_r2_mean')\n",
        "    sns.heatmap(pivot_r2, annot=True, fmt='.3f', cmap='RdYlGn', vmin=0.5, vmax=1.0, ax=ax)\n",
        "    ax.set_title('R²-based Robustness: R²_rob = min(1, R²_adv/R²_clean)')\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Clean vs Adversarial prediction scatter (one attack, one epsilon)\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "X_adv_a1 = apply_a1(X_val_scaled, 1.0, sigma_train)\n",
        "with torch.no_grad():\n",
        "    pred_adv = model(torch.FloatTensor(X_adv_a1).to(device))[0].squeeze().cpu().numpy()\n",
        "\n",
        "axes[0].scatter(pred_clean, pred_adv, alpha=0.3, s=5)\n",
        "axes[0].plot([pred_clean.min(), pred_clean.max()], [pred_clean.min(), pred_clean.max()], 'r--', label='y=x')\n",
        "axes[0].set_xlabel('Clean prediction')\n",
        "axes[0].set_ylabel('Adversarial prediction (A1, ε=1.0)')\n",
        "axes[0].set_title('Clean vs Adversarial Predictions')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1].scatter(y_val, pred_clean, alpha=0.3, s=5, label='Clean', c='blue')\n",
        "axes[1].scatter(y_val, pred_adv, alpha=0.3, s=5, label='A1 ε=1.0', c='orange')\n",
        "axes[1].set_xlabel('True return')\n",
        "axes[1].set_ylabel('Prediction')\n",
        "axes[1].set_title('True vs Predicted (Clean vs Stressed)')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Time series of predictions under stress (if dates available)\n",
        "if val_dates is not None and len(val_dates) == len(y_val):\n",
        "    fig, ax = plt.subplots(figsize=(12, 4))\n",
        "    dates = pd.to_datetime(val_dates)\n",
        "    ax.plot(dates, y_val, 'k-', alpha=0.5, label='True', linewidth=0.5)\n",
        "    ax.plot(dates, pred_clean, 'b-', alpha=0.7, label='Clean', linewidth=0.5)\n",
        "    X_adv_ts = apply_a1(X_val_scaled, 1.0, sigma_train)\n",
        "    with torch.no_grad():\n",
        "        pred_adv_ts = model(torch.FloatTensor(X_adv_ts).to(device))[0].squeeze().cpu().numpy()\n",
        "    ax.plot(dates, pred_adv_ts, 'orange', alpha=0.7, label='A1 ε=1.0', linewidth=0.5)\n",
        "    ax.set_xlabel('Date')\n",
        "    ax.set_ylabel('Return / Prediction')\n",
        "    ax.set_title('Time Series: Predictions Under Randomized Stress (A1)')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print('='*60)\n",
        "print('SUMMARY: Multi-Head Diversity (Randomized Stressors)')\n",
        "print('='*60)\n",
        "print(f'Clean: RMSE={clean_rmse:.6f}, R²={clean_r2:.6f}')\n",
        "print('\\nRobustness (RMSE-based) by attack (mean over ε):')\n",
        "for a in ATTACKS:\n",
        "    m = results_df[results_df['attack']==a]['rob_rmse_mean'].mean()\n",
        "    print(f'  {a}: {m:.4f}')\n",
        "if 'rob_r2_mean' in results_df.columns:\n",
        "    print('\\nRobustness (R²-based) by attack (mean over ε):')\n",
        "    for a in ATTACKS:\n",
        "        m = results_df[results_df['attack']==a]['rob_r2_mean'].mean()\n",
        "        print(f'  {a}: {m:.4f}')\n",
        "print('\\nRobustness (RMSE-based) by ε (mean over attacks):')\n",
        "for e in EPSILONS:\n",
        "    m = results_df[results_df['epsilon']==e]['rob_rmse_mean'].mean()\n",
        "    print(f'  ε={e}: {m:.4f}')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}