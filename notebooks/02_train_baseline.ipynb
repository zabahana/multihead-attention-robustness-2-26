{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e0ee79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small-data turn-on/off for all 6 notebook runs (01→06). Set once; applies to full pipeline.\n",
    "USE_SMALL_DATA = False  # True = small data (N_SAMPLES); False = full data\n",
    "N_SAMPLES = 10       # Max observations when USE_SMALL_DATA (e.g. 10 for quick test)\n",
    "N_EPOCHS = 1       # Max training epochs when USE_SMALL_DATA (02, 03, 04)\n",
    "# 01: applied automatically below. 02-04: epochs/n_epochs/num_epochs set automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ebde29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and setup (needed when 02-06 run in separate kernel)\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Repo root for src imports\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=False)\n",
    "except Exception:\n",
    "    pass\n",
    "def _find_repo_root():\n",
    "    cwd = Path.cwd().resolve()\n",
    "    for p in [Path('/content/drive/MyDrive/multihead-attention-robustness'),\n",
    "              Path('/content/drive/My Drive/multihead-attention-robustness'),\n",
    "              Path('/content/repo_run')]:\n",
    "        if (p / 'src').exists():\n",
    "            return p\n",
    "    drive_root = Path('/content/drive')\n",
    "    if drive_root.exists():\n",
    "        for base in [drive_root / 'MyDrive', drive_root / 'My Drive', drive_root]:\n",
    "            p = base / 'multihead-attention-robustness'\n",
    "            if p.exists() and (p / 'src').exists():\n",
    "                return p\n",
    "    p = cwd\n",
    "    for _ in range(10):\n",
    "        if (p / 'src').exists():\n",
    "            return p\n",
    "        if p.parent == p:\n",
    "            break\n",
    "        p = p.parent\n",
    "    return cwd.parent if cwd.name == 'notebooks' else cwd\n",
    "repo_root = _find_repo_root()\n",
    "sys.path.insert(0, str(repo_root))\n",
    "from src.models.feature_token_transformer import FeatureTokenTransformer, SingleHeadTransformer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "models = {}\n",
    "training_history = {}\n",
    "TRAINING_CONFIG = {\n",
    "    'ols': {}, 'ridge': {'alpha': 1.0},\n",
    "    'mlp': {'hidden_dims': [128, 64], 'learning_rate': 0.001, 'batch_size': 64, 'epochs': 100, 'patience': 10},\n",
    "    'transformer': {'d_model': 72, 'num_heads': 8, 'num_layers': 2, 'd_ff': 512, 'dropout': 0.1,\n",
    "                   'learning_rate': 0.0001, 'batch_size': 32, 'epochs': 100, 'patience': 20}\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72155dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load fresh data from master_table.csv (standalone: each notebook pulls its own data)\n",
    "data_path = repo_root / 'data' / 'cross_sectional' / 'master_table.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "if 'date' in df.columns:\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df = df.set_index('date')\n",
    "class CrossSectionalDataSplitter:\n",
    "    def __init__(self, train_start='2005-01-01', train_end='2017-12-31', val_start='2018-01-01', val_end='2019-12-31'):\n",
    "        self.train_start, self.train_end = train_start, train_end\n",
    "        self.val_start, self.val_end = val_start, val_end\n",
    "    def split(self, master_table):\n",
    "        master_table = master_table.copy()\n",
    "        master_table.index = pd.to_datetime(master_table.index)\n",
    "        return {'train': master_table.loc[self.train_start:self.train_end], 'val': master_table.loc[self.val_start:self.val_end]}\n",
    "    def prepare_features_labels(self, data):\n",
    "        if data.empty:\n",
    "            return pd.DataFrame(), pd.Series()\n",
    "        numeric_data = data.select_dtypes(include=[np.number])\n",
    "        if numeric_data.empty:\n",
    "            return pd.DataFrame(), pd.Series()\n",
    "        exclude_cols = ['mktcap', 'market_cap', 'date', 'year', 'month', 'ticker', 'permno', 'gvkey']\n",
    "        target_cols = ['return', 'returns', 'ret', 'target', 'y', 'next_return', 'forward_return', 'ret_1', 'ret_1m', 'ret_12m', 'future_return', 'returns_1d']\n",
    "        target_col = None\n",
    "        for tc in target_cols:\n",
    "            for col in numeric_data.columns:\n",
    "                if tc.lower() in col.lower() and col.lower() not in [ec.lower() for ec in exclude_cols]:\n",
    "                    target_col = col\n",
    "                    break\n",
    "            if target_col:\n",
    "                break\n",
    "        if target_col is None:\n",
    "            potential = [c for c in numeric_data.columns if c.lower() not in [ec.lower() for ec in exclude_cols]]\n",
    "            target_col = potential[-2] if len(potential) > 1 else (potential[-1] if potential else numeric_data.columns[-1])\n",
    "        feature_cols = [c for c in numeric_data.columns if c != target_col and c.lower() not in [ec.lower() for ec in exclude_cols]]\n",
    "        if not feature_cols:\n",
    "            feature_cols = [c for c in numeric_data.columns if c != target_col]\n",
    "        if not feature_cols:\n",
    "            feature_cols = numeric_data.columns[:-1].tolist()\n",
    "            target_col = numeric_data.columns[-1]\n",
    "        return numeric_data[feature_cols], numeric_data[target_col]\n",
    "splitter = CrossSectionalDataSplitter()\n",
    "data_splits = splitter.split(df)\n",
    "train_df, val_df = data_splits['train'], data_splits['val']\n",
    "X_train_df, y_train = splitter.prepare_features_labels(train_df)\n",
    "X_val_df, y_val = splitter.prepare_features_labels(val_df)\n",
    "X_train = X_train_df.fillna(0).values.astype(np.float32)\n",
    "y_train = y_train.fillna(0).values.astype(np.float32)\n",
    "X_val = X_val_df.fillna(0).values.astype(np.float32)\n",
    "y_val = y_val.fillna(0).values.astype(np.float32)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "print(f'Loaded fresh data: train {X_train_scaled.shape[0]}, val {X_val_scaled.shape[0]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec831d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = n_epochs = num_epochs = 100  # full training (standalone mode)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25d1c7f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T05:21:33.596241Z",
     "iopub.status.busy": "2026-01-23T05:21:33.595830Z",
     "iopub.status.idle": "2026-01-23T05:21:33.599455Z",
     "shell.execute_reply": "2026-01-23T05:21:33.599082Z"
    },
    "papermill": {
     "duration": 0.01293,
     "end_time": "2026-01-23T05:21:33.600354",
     "exception": false,
     "start_time": "2026-01-23T05:21:33.587424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Training configuration\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Store trained models\n",
    "models = {}\n",
    "training_history = {}\n",
    "\n",
    "# Training hyperparameters\n",
    "TRAINING_CONFIG = {\n",
    "    'ols': {},\n",
    "    'ridge': {'alpha': 1.0},\n",
    "    'mlp': {\n",
    "        'hidden_dims': [128, 64],\n",
    "        'learning_rate': 0.001,\n",
    "        'batch_size': 64,\n",
    "        'epochs': 100,\n",
    "        'patience': 10\n",
    "    },\n",
    "    'transformer': {\n",
    "        'd_model': 72,\n",
    "        'num_heads': 8,  \n",
    "        'num_layers': 2,\n",
    "        'd_ff': 512,\n",
    "        'dropout': 0.1,\n",
    "        'learning_rate': 0.0001,\n",
    "        'batch_size': 32,\n",
    "        'epochs': 100,\n",
    "        'patience': 20\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d8408f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T05:21:33.652714Z",
     "iopub.status.busy": "2026-01-23T05:21:33.652579Z",
     "iopub.status.idle": "2026-01-23T05:21:33.816071Z",
     "shell.execute_reply": "2026-01-23T05:21:33.815669Z"
    },
    "papermill": {
     "duration": 0.173248,
     "end_time": "2026-01-23T05:21:33.817032",
     "exception": false,
     "start_time": "2026-01-23T05:21:33.643784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRAINING OLS MODEL\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ OLS trained\n",
      "  Validation RMSE: 0.017520\n",
      "  Validation R²: -0.007658\n"
     ]
    }
   ],
   "source": [
    "# Train OLS (Linear Regression)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TRAINING OLS MODEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "ols_model = LinearRegression()\n",
    "ols_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "models['OLS'] = ols_model\n",
    "\n",
    "# Evaluate on validation set\n",
    "ols_pred = ols_model.predict(X_val_scaled)\n",
    "ols_rmse = np.sqrt(mean_squared_error(y_val, ols_pred))\n",
    "ols_r2 = r2_score(y_val, ols_pred)\n",
    "\n",
    "print(f\"✓ OLS trained\")\n",
    "print(f\"  Validation RMSE: {ols_rmse:.6f}\")\n",
    "print(f\"  Validation R²: {ols_r2:.6f}\")\n",
    "\n",
    "training_history['OLS'] = {'rmse': ols_rmse, 'r2': ols_r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffca9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "except ImportError:\n",
    "    print(\"XGBoost not installed. Installing...\")\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"xgboost\"])\n",
    "    import xgboost as xgb\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TRAINING XGBOOST MODEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# XGBoost configuration\n",
    "xgboost_config = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.1,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'random_state': RANDOM_SEED,\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse'\n",
    "}\n",
    "\n",
    "# Train XGBoost model\n",
    "xgboost_model = xgb.XGBRegressor(**xgboost_config)\n",
    "xgboost_model.fit(\n",
    "    X_train_scaled, \n",
    "    y_train,\n",
    "    eval_set=[(X_val_scaled, y_val)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "models['XGBoost'] = xgboost_model\n",
    "\n",
    "# Evaluate on validation set\n",
    "xgboost_pred = xgboost_model.predict(X_val_scaled)\n",
    "xgboost_rmse = np.sqrt(mean_squared_error(y_val, xgboost_pred))\n",
    "xgboost_r2 = r2_score(y_val, xgboost_pred)\n",
    "\n",
    "print(f\"✓ XGBoost trained\")\n",
    "print(f\"  Validation RMSE: {xgboost_rmse:.6f}\")\n",
    "print(f\"  Validation R²: {xgboost_r2:.6f}\")\n",
    "\n",
    "training_history['XGBoost'] = {'rmse': xgboost_rmse, 'r2': xgboost_r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a0500f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T05:21:33.837326Z",
     "iopub.status.busy": "2026-01-23T05:21:33.837049Z",
     "iopub.status.idle": "2026-01-23T05:21:33.849106Z",
     "shell.execute_reply": "2026-01-23T05:21:33.848669Z"
    },
    "papermill": {
     "duration": 0.023004,
     "end_time": "2026-01-23T05:21:33.850121",
     "exception": false,
     "start_time": "2026-01-23T05:21:33.827117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRAINING RIDGE MODEL\n",
      "================================================================================\n",
      "✓ Ridge trained\n",
      "  Validation RMSE: 0.017519\n",
      "  Validation R²: -0.007585\n"
     ]
    }
   ],
   "source": [
    "# Train Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"TRAINING RIDGE MODEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "ridge_model = Ridge(alpha=TRAINING_CONFIG['ridge']['alpha'], random_state=RANDOM_SEED)\n",
    "ridge_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "models['Ridge'] = ridge_model\n",
    "\n",
    "# Evaluate on validation set\n",
    "ridge_pred = ridge_model.predict(X_val_scaled)\n",
    "ridge_rmse = np.sqrt(mean_squared_error(y_val, ridge_pred))\n",
    "ridge_r2 = r2_score(y_val, ridge_pred)\n",
    "\n",
    "print(f\"✓ Ridge trained\")\n",
    "print(f\"  Validation RMSE: {ridge_rmse:.6f}\")\n",
    "print(f\"  Validation R²: {ridge_r2:.6f}\")\n",
    "\n",
    "training_history['Ridge'] = {'rmse': ridge_rmse, 'r2': ridge_r2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c7834cf1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T05:21:33.869317Z",
     "iopub.status.busy": "2026-01-23T05:21:33.869144Z",
     "iopub.status.idle": "2026-01-23T05:21:38.205917Z",
     "shell.execute_reply": "2026-01-23T05:21:38.205451Z"
    },
    "papermill": {
     "duration": 4.347434,
     "end_time": "2026-01-23T05:21:38.207020",
     "exception": false,
     "start_time": "2026-01-23T05:21:33.859586",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRAINING MLP MODEL\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Epoch 10/100: Train Loss=0.003197, Val Loss=0.001564\n",
      "  Epoch 20/100: Train Loss=0.002130, Val Loss=0.000643\n",
      "  Epoch 30/100: Train Loss=0.001545, Val Loss=0.000564\n",
      "  Epoch 40/100: Train Loss=0.001303, Val Loss=0.000502\n",
      "  Epoch 50/100: Train Loss=0.001119, Val Loss=0.000452\n",
      "  Epoch 60/100: Train Loss=0.001040, Val Loss=0.000423\n",
      "  Epoch 70/100: Train Loss=0.000988, Val Loss=0.000411\n",
      "  Epoch 80/100: Train Loss=0.000964, Val Loss=0.000405\n",
      "  Epoch 90/100: Train Loss=0.000936, Val Loss=0.000397\n",
      "  Epoch 100/100: Train Loss=0.000924, Val Loss=0.000394\n",
      "✓ MLP trained\n",
      "  Validation RMSE: 0.019840\n",
      "  Validation R²: -0.292290\n"
     ]
    }
   ],
   "source": [
    "# Train MLP (Multi-Layer Perceptron)\n",
    "print(\"=\" * 80)\n",
    "print(\"TRAINING MLP MODEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"Simple MLP for regression.\"\"\"\n",
    "    def __init__(self, input_dim, hidden_dims, dropout=0.1):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        prev_dim = input_dim\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(nn.Linear(prev_dim, hidden_dim))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(dropout))\n",
    "            prev_dim = hidden_dim\n",
    "        layers.append(nn.Linear(prev_dim, 1))\n",
    "        self.network = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x).squeeze(-1)\n",
    "\n",
    "mlp_config = TRAINING_CONFIG['mlp']\n",
    "mlp_model = MLP(\n",
    "    input_dim=X_train_scaled.shape[1],\n",
    "    hidden_dims=mlp_config['hidden_dims'],\n",
    "    dropout=0.1\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(mlp_model.parameters(), lr=mlp_config['learning_rate'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "# Training loop\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "X_train_tensor = torch.FloatTensor(X_train_scaled).to(device)\n",
    "y_train_tensor = torch.FloatTensor(y_train).to(device)\n",
    "X_val_tensor = torch.FloatTensor(X_val_scaled).to(device)\n",
    "y_val_tensor = torch.FloatTensor(y_val).to(device)\n",
    "\n",
    "for epoch in range(mlp_config['epochs']):\n",
    "    # Training\n",
    "    mlp_model.train()\n",
    "    optimizer.zero_grad()\n",
    "    train_pred = mlp_model(X_train_tensor)\n",
    "    train_loss = criterion(train_pred, y_train_tensor)\n",
    "    train_loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(mlp_model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Validation\n",
    "    mlp_model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_pred = mlp_model(X_val_tensor)\n",
    "        val_loss = criterion(val_pred, y_val_tensor)\n",
    "    \n",
    "    train_losses.append(train_loss.item())\n",
    "    val_losses.append(val_loss.item())\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= mlp_config['patience']:\n",
    "            print(f\"  Early stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"  Epoch {epoch+1}/{mlp_config['epochs']}: Train Loss={train_loss.item():.6f}, Val Loss={val_loss.item():.6f}\")\n",
    "\n",
    "mlp_model.eval()\n",
    "with torch.no_grad():\n",
    "    mlp_pred = mlp_model(X_val_tensor).cpu().numpy()\n",
    "\n",
    "mlp_rmse = np.sqrt(mean_squared_error(y_val, mlp_pred))\n",
    "mlp_r2 = r2_score(y_val, mlp_pred)\n",
    "\n",
    "models['MLP'] = mlp_model\n",
    "print(f\"✓ MLP trained\")\n",
    "print(f\"  Validation RMSE: {mlp_rmse:.6f}\")\n",
    "print(f\"  Validation R²: {mlp_r2:.6f}\")\n",
    "\n",
    "training_history['MLP'] = {'rmse': mlp_rmse, 'r2': mlp_r2, 'train_losses': train_losses, 'val_losses': val_losses}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bf31c0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T05:21:38.229037Z",
     "iopub.status.busy": "2026-01-23T05:21:38.228733Z",
     "iopub.status.idle": "2026-01-23T05:25:31.356411Z",
     "shell.execute_reply": "2026-01-23T05:25:31.355933Z"
    },
    "papermill": {
     "duration": 233.149968,
     "end_time": "2026-01-23T05:25:31.368392",
     "exception": false,
     "start_time": "2026-01-23T05:21:38.218424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "TRAINING TRANSFORMER MODELS\n",
      "================================================================================\n",
      "\n",
      "Training Single-Head Transformer...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Single-Head - Epoch 10/100: Train Loss=0.000589, Val Loss=0.000290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Single-Head - Epoch 20/100: Train Loss=0.000513, Val Loss=0.000291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Single-Head - Epoch 30/100: Train Loss=0.000480, Val Loss=0.000284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Single-Head - Epoch 40/100: Train Loss=0.000474, Val Loss=0.000282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Single-Head - Epoch 50/100: Train Loss=0.000454, Val Loss=0.000278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Single-Head - Epoch 60/100: Train Loss=0.000442, Val Loss=0.000276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Single-Head - Epoch 70/100: Train Loss=0.000430, Val Loss=0.000274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Single-Head - Epoch 80/100: Train Loss=0.000425, Val Loss=0.000274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Single-Head - Epoch 90/100: Train Loss=0.000421, Val Loss=0.000274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Single-Head: Early stopping at epoch 95\n",
      "Single-Head trained - RMSE: 0.016555, R²: 0.100279\n"
     ]
    }
   ],
   "source": [
    "# Train Transformer Models\n",
    "print(\"=\" * 80)\n",
    "print(\"TRAINING TRANSFORMER MODELS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "def train_transformer(model, model_name, X_train, y_train, X_val, y_val, config, device='cpu'):\n",
    "    \"\"\"Train a transformer model.\"\"\"\n",
    "    model = model.to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config['learning_rate'])\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "    \n",
    "    # Convert to tensors\n",
    "    X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "    y_train_tensor = torch.FloatTensor(y_train).to(device)\n",
    "    X_val_tensor = torch.FloatTensor(X_val).to(device)\n",
    "    y_val_tensor = torch.FloatTensor(y_val).to(device)\n",
    "    \n",
    "    # Handle feature dimension mismatch\n",
    "    num_features = model.num_features if hasattr(model, 'num_features') else model.model.num_features\n",
    "    \n",
    "    if X_train.shape[1] != num_features:\n",
    "        if X_train.shape[1] < num_features:\n",
    "            # Pad\n",
    "            padding_train = np.zeros((X_train.shape[0], num_features - X_train.shape[1]))\n",
    "            padding_val = np.zeros((X_val.shape[0], num_features - X_val.shape[1]))\n",
    "            X_train_tensor = torch.FloatTensor(np.hstack([X_train, padding_train])).to(device)\n",
    "            X_val_tensor = torch.FloatTensor(np.hstack([X_val, padding_val])).to(device)\n",
    "        else:\n",
    "            # Truncate\n",
    "            X_train_tensor = torch.FloatTensor(X_train[:, :num_features]).to(device)\n",
    "            X_val_tensor = torch.FloatTensor(X_val[:, :num_features]).to(device)\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    batch_size = config['batch_size']\n",
    "    n_batches = (len(X_train_tensor) + batch_size - 1) // batch_size\n",
    "    \n",
    "    for epoch in range(config['epochs']):\n",
    "        # Training\n",
    "        model.train()\n",
    "        epoch_train_loss = 0.0\n",
    "        \n",
    "        for i in range(0, len(X_train_tensor), batch_size):\n",
    "            batch_X = X_train_tensor[i:i+batch_size]\n",
    "            batch_y = y_train_tensor[i:i+batch_size]\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            pred = model(batch_X)\n",
    "            if isinstance(pred, tuple):\n",
    "                pred = pred[0]\n",
    "            loss = criterion(pred.squeeze(), batch_y)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_train_loss += loss.item()\n",
    "        \n",
    "        epoch_train_loss /= n_batches\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_pred = model(X_val_tensor)\n",
    "            if isinstance(val_pred, tuple):\n",
    "                val_pred = val_pred[0]\n",
    "            val_loss = criterion(val_pred.squeeze(), y_val_tensor)\n",
    "        \n",
    "        train_losses.append(epoch_train_loss)\n",
    "        val_losses.append(val_loss.item())\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= config['patience']:\n",
    "                print(f\"  {model_name}: Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"  {model_name} - Epoch {epoch+1}/{config['epochs']}: Train Loss={epoch_train_loss:.6f}, Val Loss={val_loss.item():.6f}\")\n",
    "    \n",
    "    # Final evaluation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        final_pred = model(X_val_tensor)\n",
    "        if isinstance(final_pred, tuple):\n",
    "            final_pred = final_pred[0]\n",
    "        final_pred = final_pred.squeeze().cpu().numpy()\n",
    "    \n",
    "    return model, final_pred, train_losses, val_losses\n",
    "\n",
    "# Train Single-Head Transformer\n",
    "print(\"\\nTraining Single-Head Transformer...\")\n",
    "single_head_model = SingleHeadTransformer(\n",
    "    num_features=X_train_scaled.shape[1],\n",
    "    d_model=TRAINING_CONFIG['transformer']['d_model'],\n",
    "    num_layers=TRAINING_CONFIG['transformer']['num_layers']\n",
    ")\n",
    "single_head_model, single_head_pred, sh_train_losses, sh_val_losses = train_transformer(\n",
    "    single_head_model, 'Single-Head', X_train_scaled, y_train, X_val_scaled, y_val,\n",
    "    TRAINING_CONFIG['transformer'], device\n",
    ")\n",
    "\n",
    "single_head_rmse = np.sqrt(mean_squared_error(y_val, single_head_pred))\n",
    "single_head_r2 = r2_score(y_val, single_head_pred)\n",
    "\n",
    "models['Single-Head'] = single_head_model\n",
    "print(f\"Single-Head trained - RMSE: {single_head_rmse:.6f}, R²: {single_head_r2:.6f}\")\n",
    "training_history['Single-Head'] = {'rmse': single_head_rmse, 'r2': single_head_r2, 'train_losses': sh_train_losses, 'val_losses': sh_val_losses}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "89a26697",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T05:25:31.390338Z",
     "iopub.status.busy": "2026-01-23T05:25:31.390131Z",
     "iopub.status.idle": "2026-01-23T05:29:44.411184Z",
     "shell.execute_reply": "2026-01-23T05:29:44.410761Z"
    },
    "papermill": {
     "duration": 253.043123,
     "end_time": "2026-01-23T05:29:44.422404",
     "exception": false,
     "start_time": "2026-01-23T05:25:31.379281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Multi-Head Transformer...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Multi-Head - Epoch 10/100: Train Loss=0.000616, Val Loss=0.000298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Multi-Head - Epoch 20/100: Train Loss=0.000545, Val Loss=0.000303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Multi-Head - Epoch 30/100: Train Loss=0.000511, Val Loss=0.000292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Multi-Head - Epoch 40/100: Train Loss=0.000492, Val Loss=0.000286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Multi-Head - Epoch 50/100: Train Loss=0.000473, Val Loss=0.000282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Multi-Head - Epoch 60/100: Train Loss=0.000456, Val Loss=0.000280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Multi-Head - Epoch 70/100: Train Loss=0.000438, Val Loss=0.000273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Multi-Head - Epoch 80/100: Train Loss=0.000427, Val Loss=0.000271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Multi-Head - Epoch 90/100: Train Loss=0.000420, Val Loss=0.000270\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Multi-Head - Epoch 100/100: Train Loss=0.000416, Val Loss=0.000269\n",
      "✓ Multi-Head trained - RMSE: 0.016388, R²: 0.118330\n",
      "CPU times: user 4min 10s, sys: 1.35 s, total: 4min 11s\n",
      "Wall time: 4min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Train Multi-Head Transformer\n",
    "print(\"\\nTraining Multi-Head Transformer...\")\n",
    "multi_head_model = FeatureTokenTransformer(\n",
    "    num_features=X_train_scaled.shape[1],\n",
    "    d_model=TRAINING_CONFIG['transformer']['d_model'],\n",
    "    num_heads=TRAINING_CONFIG['transformer']['num_heads'],\n",
    "    num_layers=TRAINING_CONFIG['transformer']['num_layers'],\n",
    "    d_ff=TRAINING_CONFIG['transformer']['d_ff'],\n",
    "    dropout=TRAINING_CONFIG['transformer']['dropout'],\n",
    "    use_head_diversity=False\n",
    ")\n",
    "multi_head_model, multi_head_pred, mh_train_losses, mh_val_losses = train_transformer(\n",
    "    multi_head_model, 'Multi-Head', X_train_scaled, y_train, X_val_scaled, y_val,\n",
    "    TRAINING_CONFIG['transformer'], device\n",
    ")\n",
    "\n",
    "multi_head_rmse = np.sqrt(mean_squared_error(y_val, multi_head_pred))\n",
    "multi_head_r2 = r2_score(y_val, multi_head_pred)\n",
    "\n",
    "models['Multi-Head'] = multi_head_model\n",
    "print(f\"✓ Multi-Head trained - RMSE: {multi_head_rmse:.6f}, R²: {multi_head_r2:.6f}\")\n",
    "training_history['Multi-Head'] = {'rmse': multi_head_rmse, 'r2': multi_head_r2, 'train_losses': mh_train_losses, 'val_losses': mh_val_losses}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e0ead95d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T05:29:44.444016Z",
     "iopub.status.busy": "2026-01-23T05:29:44.443729Z",
     "iopub.status.idle": "2026-01-23T05:33:30.073050Z",
     "shell.execute_reply": "2026-01-23T05:33:30.072663Z"
    },
    "papermill": {
     "duration": 225.641404,
     "end_time": "2026-01-23T05:33:30.074044",
     "exception": false,
     "start_time": "2026-01-23T05:29:44.432640",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Multi-Head Diversity Transformer...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Multi-Head Diversity - Epoch 10/100: Train Loss=0.000615, Val Loss=0.000313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Multi-Head Diversity - Epoch 20/100: Train Loss=0.000549, Val Loss=0.000302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Multi-Head Diversity - Epoch 30/100: Train Loss=0.000522, Val Loss=0.000291\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Multi-Head Diversity - Epoch 40/100: Train Loss=0.000495, Val Loss=0.000283\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Multi-Head Diversity - Epoch 50/100: Train Loss=0.000478, Val Loss=0.000279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Multi-Head Diversity - Epoch 60/100: Train Loss=0.000460, Val Loss=0.000276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Multi-Head Diversity - Epoch 70/100: Train Loss=0.000448, Val Loss=0.000275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Multi-Head Diversity - Epoch 80/100: Train Loss=0.000435, Val Loss=0.000276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Multi-Head Diversity - Epoch 90/100: Train Loss=0.000422, Val Loss=0.000274\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Multi-Head Diversity: Early stopping at epoch 92\n",
      "✓ Multi-Head Diversity trained - RMSE: 0.016533, R²: 0.102619\n",
      "\n",
      "================================================================================\n",
      "ALL MODELS TRAINED\n",
      "================================================================================\n",
      "Total models trained: 6\n",
      "\n",
      "Validation Results Summary:\n",
      "  OLS: RMSE=0.017520, R²=-0.007658\n",
      "  Ridge: RMSE=0.017519, R²=-0.007585\n",
      "  MLP: RMSE=0.019840, R²=-0.292290\n",
      "  Single-Head: RMSE=0.016555, R²=0.100279\n",
      "  Multi-Head: RMSE=0.016388, R²=0.118330\n",
      "  Multi-Head Diversity: RMSE=0.016533, R²=0.102619\n"
     ]
    }
   ],
   "source": [
    "# Train Multi-Head Diversity Transformer\n",
    "print(\"\\nTraining Multi-Head Diversity Transformer...\")\n",
    "multi_head_diversity_model = FeatureTokenTransformer(\n",
    "    num_features=X_train_scaled.shape[1],\n",
    "    d_model=TRAINING_CONFIG['transformer']['d_model'],\n",
    "    num_heads=TRAINING_CONFIG['transformer']['num_heads'],\n",
    "    num_layers=TRAINING_CONFIG['transformer']['num_layers'],\n",
    "    d_ff=TRAINING_CONFIG['transformer']['d_ff'],\n",
    "    dropout=TRAINING_CONFIG['transformer']['dropout'],\n",
    "    use_head_diversity=True,\n",
    "    diversity_weight=0.01\n",
    ")\n",
    "multi_head_diversity_model, mhd_pred, mhd_train_losses, mhd_val_losses = train_transformer(\n",
    "    multi_head_diversity_model, 'Multi-Head Diversity', X_train_scaled, y_train, X_val_scaled, y_val,\n",
    "    TRAINING_CONFIG['transformer'], device\n",
    ")\n",
    "\n",
    "multi_head_diversity_rmse = np.sqrt(mean_squared_error(y_val, mhd_pred))\n",
    "multi_head_diversity_r2 = r2_score(y_val, mhd_pred)\n",
    "\n",
    "models['Multi-Head Diversity'] = multi_head_diversity_model\n",
    "print(f\"✓ Multi-Head Diversity trained - RMSE: {multi_head_diversity_rmse:.6f}, R²: {multi_head_diversity_r2:.6f}\")\n",
    "training_history['Multi-Head Diversity'] = {'rmse': multi_head_diversity_rmse, 'r2': multi_head_diversity_r2, 'train_losses': mhd_train_losses, 'val_losses': mhd_val_losses}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ALL MODELS TRAINED\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total models trained: {len(models)}\")\n",
    "print(\"\\nValidation Results Summary:\")\n",
    "for name, metrics in training_history.items():\n",
    "    print(f\"  {name}: RMSE={metrics['rmse']:.6f}, R²={metrics['r2']:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8f8c043",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-23T05:33:30.095935Z",
     "iopub.status.busy": "2026-01-23T05:33:30.095552Z",
     "iopub.status.idle": "2026-01-23T05:33:30.372563Z",
     "shell.execute_reply": "2026-01-23T05:33:30.372170Z"
    },
    "papermill": {
     "duration": 0.288278,
     "end_time": "2026-01-23T05:33:30.373547",
     "exception": false,
     "start_time": "2026-01-23T05:33:30.085269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making predictions on validation set...\n",
      "OLS:\n",
      "  RMSE: 0.017520\n",
      "  R²: -0.007658\n",
      "\n",
      "Ridge:\n",
      "  RMSE: 0.017519\n",
      "  R²: -0.007585\n",
      "\n",
      "MLP:\n",
      "  RMSE: 0.019840\n",
      "  R²: -0.292290\n",
      "\n",
      "Single-Head:\n",
      "  RMSE: 0.016555\n",
      "  R²: 0.100279\n",
      "\n",
      "Multi-Head:\n",
      "  RMSE: 0.016388\n",
      "  R²: 0.118330\n",
      "\n",
      "Multi-Head Diversity:\n",
      "  RMSE: 0.016533\n",
      "  R²: 0.102619\n",
      "\n",
      "================================================================================\n",
      "MODEL COMPARISON SUMMARY\n",
      "================================================================================\n",
      "               Model     RMSE        R²\n",
      "          Multi-Head 0.016388  0.118330\n",
      "Multi-Head Diversity 0.016533  0.102619\n",
      "         Single-Head 0.016555  0.100279\n",
      "               Ridge 0.017519 -0.007585\n",
      "                 OLS 0.017520 -0.007658\n",
      "                 MLP 0.019840 -0.292290\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def make_predictions(model, X, device='cpu', batch_size=128, is_sklearn=False):\n",
    "    \"\"\"Make predictions with a model (deterministic mode).\"\"\"\n",
    "    if is_sklearn:\n",
    "        # sklearn models\n",
    "        return model.predict(X)\n",
    "    \n",
    "    # PyTorch models\n",
    "    model.eval()\n",
    "    \n",
    "    # Ensure deterministic mode - disable dropout\n",
    "    with torch.no_grad():\n",
    "        for module in model.modules():\n",
    "            if isinstance(module, nn.Dropout):\n",
    "                module.eval()\n",
    "        \n",
    "        predictions = []\n",
    "        \n",
    "        # Get num_features - handle both FeatureTokenTransformer and SingleHeadTransformer\n",
    "        if hasattr(model, 'num_features'):\n",
    "            num_features = model.num_features\n",
    "        elif hasattr(model, 'model') and hasattr(model.model, 'num_features'):\n",
    "            # SingleHeadTransformer wraps FeatureTokenTransformer in self.model\n",
    "            num_features = model.model.num_features\n",
    "        else:\n",
    "            # Fallback: use input dimension\n",
    "            num_features = X.shape[1]\n",
    "        \n",
    "        for i in range(0, len(X), batch_size):\n",
    "            batch = X[i:i+batch_size]\n",
    "            X_tensor = torch.FloatTensor(batch).to(device)\n",
    "            \n",
    "            # Handle padding if needed\n",
    "            if X_tensor.shape[1] != num_features:\n",
    "                if X_tensor.shape[1] < num_features:\n",
    "                    padding = torch.zeros(X_tensor.shape[0], num_features - X_tensor.shape[1]).to(device)\n",
    "                    X_tensor = torch.cat([X_tensor, padding], dim=1)\n",
    "                else:\n",
    "                    X_tensor = X_tensor[:, :num_features]\n",
    "            \n",
    "            pred = model(X_tensor)\n",
    "            if isinstance(pred, tuple):\n",
    "                pred = pred[0]\n",
    "            predictions.append(pred.cpu().numpy())\n",
    "    \n",
    "    return np.concatenate(predictions, axis=0).flatten()\n",
    "\n",
    "# Make predictions on validation set\n",
    "print(\"Making predictions on validation set...\")\n",
    "predictions = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    is_sklearn = name in ['OLS', 'Ridge', 'XGBoost']\n",
    "    pred = make_predictions(model, X_val_scaled, device, is_sklearn=is_sklearn)\n",
    "    predictions[name] = pred.flatten()\n",
    "    \n",
    "    # Calculate metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, pred))\n",
    "    r2 = r2_score(y_val, pred)\n",
    "    \n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  RMSE: {rmse:.6f}\")\n",
    "    print(f\"  R²: {r2:.6f}\")\n",
    "    print()\n",
    "comparison_data = []\n",
    "for name in ['OLS', 'Ridge', 'XGBoost', 'MLP', 'Single-Head', 'Multi-Head', 'Multi-Head Diversity']:\n",
    "    if name in training_history:\n",
    "        comparison_data.append({\n",
    "            'Model': name,\n",
    "            'RMSE': training_history[name]['rmse'],\n",
    "            'R²': training_history[name]['r2']\n",
    "        })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values('R²', ascending=False)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"MODEL COMPARISON SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Visualize comparison\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# RMSE comparison\n",
    "ax1.barh(comparison_df['Model'], comparison_df['RMSE'])\n",
    "ax1.set_xlabel('RMSE', fontsize=12)\n",
    "ax1.set_title('RMSE Comparison (Lower is Better)', fontsize=14)\n",
    "ax1.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# R² comparison\n",
    "ax2.barh(comparison_df['Model'], comparison_df['R²'])\n",
    "ax2.set_xlabel('R²', fontsize=12)\n",
    "ax2.set_title('R² Comparison (Higher is Better)', fontsize=14)\n",
    "ax2.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8769c03d",
   "metadata": {
    "papermill": {
     "duration": 0.010828,
     "end_time": "2026-01-23T05:33:30.396933",
     "exception": false,
     "start_time": "2026-01-23T05:33:30.386105",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Adversarial Training (A1-A4 Attacks)\n",
    "\n",
    "Train transformer models with adversarial training against A1-A4 attacks to improve robustness."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 10661.980152,
   "end_time": "2026-01-23T08:19:09.986181",
   "environment_variables": {},
   "exception": null,
   "input_path": "notebooks/Final_Models_Demo_6heads.ipynb",
   "output_path": "Final_Models_Demo_6heads_executed.ipynb",
   "parameters": {},
   "start_time": "2026-01-23T05:21:28.006029",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
